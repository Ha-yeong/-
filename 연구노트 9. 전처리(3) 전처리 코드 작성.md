성균관대학교 </br>
심하영 </br>
2018.02.27.


## 전처리 전체 코드

불필요한 한글 자음, 모음, 문장 부호 등을 제거하기 위한 전처리 작업과 </br>
한글로 된 리뷰를 구글 번역기를 사용하여 영어로 번역해주는 코드이다. </br>

### def filtering_sentence(line)

파이썬의 're' 라이브러리를 이용하여 전처리 작업을 수행했다. </br>
1) 정규표현식을 활용하여 한글 자/모음을 마침표로 치환했다. (ㅋㅋ나 ㅎㅎ, ㅠㅠ 등은 대부분의 경우 문장 끝에 사용하기 때문)
2) 기호 - _ @ # $ * ( ) { } : "를 제거했다.
3) 기호 . ! ~ ; ^를 마침표로 치환했다.
4) 기호 &을 and로 치환했다.
5) ? ?? ??? 등 한개 이상의 물음표를 하나의 물음표로 치환했다.
6) , ,, ,,, 등 한개 이상의 쉼표를 하나의 쉼표로 치환했다.
7) 한칸 이상의 공백을 한칸의 공백으로 치환했다.
8) 마침표 앞에 공백이 있으면 제거했다.
9) 마침표 뒤에 공백 여러 칸이 있으면 한칸으로 치환했다.

### def_translate_sentence(line)

쿼리 문자열(Query String)이란 사용자가 웹 프로그램으로 입력 데이터를 전달하는 방법의 일종이다. </br>
이 방법은 URL 주소 뒤에 입력 데이터를 함께 제공하는 방법이다. </br>
구글 번역기(https://translate.google.com/)에서 번역을 수행한 후의 URL은 </br>
https://translate.google.com/?sl=ko&tl=en&text=%EB%82%98%EB%8(..이하 생략)으로, </br>
구글 번역기의 주소 뒤에 번역을 원하는 문장의 query string을 추가한 것이라는 것을 알게 되었다. </br>
query string은 파이썬의 urlencode 함수를 이용하여 얻을 수 있었고, </br>
BeautifulSoup로 html 코드를 파싱해서 번역한 결과 데이터를 얻을 수 있었다.

### def is_Korean(line)

해당 라인이 영어로 작성되었는지 한글로 작성되었는지를 판별하는 함수이다. </br>
isalpha()와 같은 함수를 사용하면 손쉽게 한글인지 영어인지를 구분할 수 있을 거라고 생각했는데 </br>
한글과 영어 모두에 대해 true 값을 반환하여 사용할 수 없었다. </br>
대신 알파벳의 아스키코드는 200 이하의 값을 가지는 반면 한글의 아스키코드는 40000 언저리의 값을 가진다는 점을 활용하였다. </br>
하지만 영어 단어로 시작하는 한글 리뷰의 경우 영어로 작성된 것이라고 판별되어, 전처리 후 약간의 수작업이 필요했다. </br>

### def language_processing(title)

주어진 파일을 한 줄씩 읽어내려가면서 전처리와 번역을 수행하고, 그 결과를 새로운 파일에 써내려가는 함수이다. </br>
파이썬이 익숙하지 않아서 중간중간에 시행착오가 있었고 프로그램의 효율을 높일 수 있는 방법도 많은 것 같아서 </br>
아쉬움이 많이 남는다.


~~~
# -*- coding: utf-8 -*-

from bs4 import BeautifulSoup
import urllib.parse
import urllib.request
import requests
import re
import os

def filtering_sentence(line):
    line = re.sub('[ㄱ-ㅎㅏ-ㅣ]', '.', line)
    line = re.sub('[-_@#$*$(){}:"]', '', line)
    line = re.sub('[.!~;^]+', '.', line)
    line = re.sub('[&]+', ' and ', line)
    line = re.sub('[?]+', '?', line)
    line = re.sub('[,]+', ',', line)
    line = re.sub('[ ]+', ' ', line)
    line = re.sub('[ ]+[.]', '.', line)
    line = re.sub('[.][ ]+', '. ', line)
    line = re.sub('[.!~;^]+', '.', line)
    return line

def translate_sentence(line):
    data = {'sl':'ko', 'tl':'en', 'text':line}    
    querystring = urllib.parse.urlencode(data)

    url = 'https://translate.google.com/' + '?' + querystring
    req = requests.get(url)
    html = req.text
    req.close()
    
    soup = BeautifulSoup(html, 'html.parser')
    return soup.find('span', id='result_box').text

def is_Korean(line):
    if len(line) > 0:
        sum = 0
        for i in range(0, len(line)):
            sum = sum + ord(line[i:i+1])
            if sum > 200 * (i + 1):
                return True
            if i == 6:
                return False

def language_processing(title):
    newTitle = title.split('.txt')[0] + '_.txt'
    fr = open(title, 'r')
    fw = open(newTitle, 'w')

    saveLine = ''
    count = 0

    while True:
        line = fr.readline()
        if not line: #파일의 끝
            break

        line = line.strip('\n')
        if line.isdigit(): #숫자인 경우
            saveLine = filtering_sentence(saveLine)
            fw.write(saveLine + '\n')
            fw.write(line + '\n')
            saveLine = ''
            count = 0
            continue

        line = filtering_sentence(line) #필터링
        if is_Korean(line):
            line = translate_sentence(line) #번역
            
        if count == 0:
            saveLine = line
            count = count + 1
        else:
            saveLine = saveLine + ' ' + line
        
    fw.write(saveLine + '\n')
    fr.close()
    fw.close()

path_dir = '/Users/hayeongshim/PycharmProjects'
file_list = os.listdir(path_dir)
file_list.sort()
print(file_list)

for i in range(2, 4):
    print(file_list[i])
    language_processing(file_list[i])
~~~


## 참고

- https://wikidocs.net/4308 (정규표현식)
